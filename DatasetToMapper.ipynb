{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Digits Dataset\n",
    "\n",
    "This digits example shows two ways of customizing the tooltips options in the HTML visualization. It generates the visualization with tooltips set as the y-label, or number of the image. The second generated result uses the actual image in the tooltips.\n",
    "\n",
    "`Visualization with y-label tooltip <../../_static/digits_ylabel_tooltips.html>`_\n",
    "\n",
    "`Visualization with custom tooltips <../../_static/digits_custom_tooltips.html>`_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\mark_\\anaconda3\\lib\\site-packages (8.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper(verbose=2)\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: TSNE()\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (1797, 64)\n",
      "\n",
      "..Projecting data using: \n",
      "\tTSNE(verbose=2)\n",
      "\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1797 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1797 samples in 0.119s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1797\n",
      "[t-SNE] Computed conditional probabilities for sample 1797 / 1797\n",
      "[t-SNE] Mean sigma: 157.044611\n",
      "[t-SNE] Computed conditional probabilities in 0.130s\n",
      "[t-SNE] Iteration 50: error = 75.2938538, gradient norm = 0.1244358 (50 iterations in 0.261s)\n",
      "[t-SNE] Iteration 100: error = 63.8273544, gradient norm = 0.0456754 (50 iterations in 0.206s)\n",
      "[t-SNE] Iteration 150: error = 62.3973579, gradient norm = 0.0293449 (50 iterations in 0.225s)\n",
      "[t-SNE] Iteration 200: error = 61.9336815, gradient norm = 0.0246261 (50 iterations in 0.222s)\n",
      "[t-SNE] Iteration 250: error = 61.7194595, gradient norm = 0.0314047 (50 iterations in 0.226s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 61.719460\n",
      "[t-SNE] Iteration 300: error = 1.0455197, gradient norm = 0.0008759 (50 iterations in 0.213s)\n",
      "[t-SNE] Iteration 350: error = 0.8715563, gradient norm = 0.0003621 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 400: error = 0.8160766, gradient norm = 0.0002493 (50 iterations in 0.191s)\n",
      "[t-SNE] Iteration 450: error = 0.7915993, gradient norm = 0.0001846 (50 iterations in 0.199s)\n",
      "[t-SNE] Iteration 500: error = 0.7791265, gradient norm = 0.0001582 (50 iterations in 0.201s)\n",
      "[t-SNE] Iteration 550: error = 0.7707375, gradient norm = 0.0001508 (50 iterations in 0.187s)\n",
      "[t-SNE] Iteration 600: error = 0.7651623, gradient norm = 0.0001213 (50 iterations in 0.192s)\n",
      "[t-SNE] Iteration 650: error = 0.7607247, gradient norm = 0.0001057 (50 iterations in 0.189s)\n",
      "[t-SNE] Iteration 700: error = 0.7569431, gradient norm = 0.0001026 (50 iterations in 0.197s)\n",
      "[t-SNE] Iteration 750: error = 0.7539478, gradient norm = 0.0000943 (50 iterations in 0.191s)\n",
      "[t-SNE] Iteration 800: error = 0.7515422, gradient norm = 0.0000974 (50 iterations in 0.192s)\n",
      "[t-SNE] Iteration 850: error = 0.7494568, gradient norm = 0.0000935 (50 iterations in 0.220s)\n",
      "[t-SNE] Iteration 900: error = 0.7476696, gradient norm = 0.0000863 (50 iterations in 0.203s)\n",
      "[t-SNE] Iteration 950: error = 0.7462196, gradient norm = 0.0000861 (50 iterations in 0.211s)\n",
      "[t-SNE] Iteration 1000: error = 0.7448296, gradient norm = 0.0000914 (50 iterations in 0.191s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.744830\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "Mapping on data shaped (1797, 2) using lens shaped (1797, 2)\n",
      "\n",
      "Minimal points in hypercube before clustering: 15\n",
      "Creating 1225 hypercubes.\n",
      "Cube_0 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 1.\n",
      "   > Found 1 clusters in hypercube 2.\n",
      "Cube_3 is empty.\n",
      "\n",
      "Cube_4 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 5.\n",
      "   > Found 1 clusters in hypercube 6.\n",
      "   > Found 1 clusters in hypercube 7.\n",
      "Cube_8 is empty.\n",
      "\n",
      "Cube_9 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 10.\n",
      "   > Found 1 clusters in hypercube 11.\n",
      "   > Found 1 clusters in hypercube 12.\n",
      "Cube_13 is empty.\n",
      "\n",
      "Cube_14 is empty.\n",
      "\n",
      "Cube_15 is empty.\n",
      "\n",
      "Cube_16 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 17.\n",
      "   > Found 1 clusters in hypercube 18.\n",
      "   > Found 1 clusters in hypercube 19.\n",
      "Cube_20 is empty.\n",
      "\n",
      "Cube_21 is empty.\n",
      "\n",
      "Cube_22 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 23.\n",
      "   > Found 1 clusters in hypercube 24.\n",
      "Cube_25 is empty.\n",
      "\n",
      "Cube_26 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 27.\n",
      "   > Found 1 clusters in hypercube 28.\n",
      "   > Found 1 clusters in hypercube 29.\n",
      "Cube_30 is empty.\n",
      "\n",
      "Cube_31 is empty.\n",
      "\n",
      "Cube_32 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 33.\n",
      "   > Found 1 clusters in hypercube 34.\n",
      "   > Found 1 clusters in hypercube 35.\n",
      "   > Found 1 clusters in hypercube 36.\n",
      "Cube_37 is empty.\n",
      "\n",
      "Cube_38 is empty.\n",
      "\n",
      "Cube_39 is empty.\n",
      "\n",
      "Cube_40 is empty.\n",
      "\n",
      "Cube_41 is empty.\n",
      "\n",
      "Cube_42 is empty.\n",
      "\n",
      "Cube_43 is empty.\n",
      "\n",
      "Cube_44 is empty.\n",
      "\n",
      "Cube_45 is empty.\n",
      "\n",
      "Cube_46 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 47.\n",
      "   > Found 1 clusters in hypercube 48.\n",
      "Cube_49 is empty.\n",
      "\n",
      "Cube_50 is empty.\n",
      "\n",
      "Cube_51 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 52.\n",
      "   > Found 1 clusters in hypercube 53.\n",
      "   > Found 1 clusters in hypercube 54.\n",
      "   > Found 1 clusters in hypercube 55.\n",
      "Cube_56 is empty.\n",
      "\n",
      "Cube_57 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 58.\n",
      "Cube_59 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 60.\n",
      "   > Found 1 clusters in hypercube 61.\n",
      "Cube_62 is empty.\n",
      "\n",
      "Cube_63 is empty.\n",
      "\n",
      "Cube_64 is empty.\n",
      "\n",
      "Cube_65 is empty.\n",
      "\n",
      "Cube_66 is empty.\n",
      "\n",
      "Cube_67 is empty.\n",
      "\n",
      "Cube_68 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 69.\n",
      "Cube_70 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 71.\n",
      "   > Found 1 clusters in hypercube 72.\n",
      "Cube_73 is empty.\n",
      "\n",
      "Cube_74 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 75.\n",
      "Cube_76 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 77.\n",
      "   > Found 1 clusters in hypercube 78.\n",
      "   > Found 1 clusters in hypercube 79.\n",
      "Cube_80 is empty.\n",
      "\n",
      "Cube_81 is empty.\n",
      "\n",
      "Cube_82 is empty.\n",
      "\n",
      "Cube_83 is empty.\n",
      "\n",
      "Cube_84 is empty.\n",
      "\n",
      "Cube_85 is empty.\n",
      "\n",
      "Cube_86 is empty.\n",
      "\n",
      "Cube_87 is empty.\n",
      "\n",
      "Cube_88 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 89.\n",
      "Cube_90 is empty.\n",
      "\n",
      "Cube_91 is empty.\n",
      "\n",
      "Cube_92 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 93.\n",
      "   > Found 1 clusters in hypercube 94.\n",
      "   > Found 1 clusters in hypercube 95.\n",
      "Cube_96 is empty.\n",
      "\n",
      "Cube_97 is empty.\n",
      "\n",
      "Cube_98 is empty.\n",
      "\n",
      "Cube_99 is empty.\n",
      "\n",
      "Cube_100 is empty.\n",
      "\n",
      "Cube_101 is empty.\n",
      "\n",
      "Cube_102 is empty.\n",
      "\n",
      "Cube_103 is empty.\n",
      "\n",
      "Cube_104 is empty.\n",
      "\n",
      "Cube_105 is empty.\n",
      "\n",
      "Cube_106 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 107.\n",
      "   > Found 1 clusters in hypercube 108.\n",
      "   > Found 1 clusters in hypercube 109.\n",
      "Cube_110 is empty.\n",
      "\n",
      "Cube_111 is empty.\n",
      "\n",
      "Cube_112 is empty.\n",
      "\n",
      "Cube_113 is empty.\n",
      "\n",
      "Cube_114 is empty.\n",
      "\n",
      "Cube_115 is empty.\n",
      "\n",
      "Cube_116 is empty.\n",
      "\n",
      "Cube_117 is empty.\n",
      "\n",
      "Cube_118 is empty.\n",
      "\n",
      "Cube_119 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 120.\n",
      "   > Found 1 clusters in hypercube 121.\n",
      "Cube_122 is empty.\n",
      "\n",
      "Cube_123 is empty.\n",
      "\n",
      "Cube_124 is empty.\n",
      "\n",
      "Cube_125 is empty.\n",
      "\n",
      "Cube_126 is empty.\n",
      "\n",
      "Cube_127 is empty.\n",
      "\n",
      "Cube_128 is empty.\n",
      "\n",
      "Cube_129 is empty.\n",
      "\n",
      "Cube_130 is empty.\n",
      "\n",
      "Cube_131 is empty.\n",
      "\n",
      "Cube_132 is empty.\n",
      "\n",
      "Cube_133 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 134.\n",
      "Cube_135 is empty.\n",
      "\n",
      "Cube_136 is empty.\n",
      "\n",
      "Cube_137 is empty.\n",
      "\n",
      "Cube_138 is empty.\n",
      "\n",
      "Cube_139 is empty.\n",
      "\n",
      "Cube_140 is empty.\n",
      "\n",
      "Cube_141 is empty.\n",
      "\n",
      "Cube_142 is empty.\n",
      "\n",
      "Cube_143 is empty.\n",
      "\n",
      "Cube_144 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 145.\n",
      "Cube_146 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 147.\n",
      "   > Found 1 clusters in hypercube 148.\n",
      "Cube_149 is empty.\n",
      "\n",
      "Cube_150 is empty.\n",
      "\n",
      "Cube_151 is empty.\n",
      "\n",
      "Cube_152 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 153.\n",
      "Cube_154 is empty.\n",
      "\n",
      "Cube_155 is empty.\n",
      "\n",
      "Cube_156 is empty.\n",
      "\n",
      "Cube_157 is empty.\n",
      "\n",
      "Cube_158 is empty.\n",
      "\n",
      "Cube_159 is empty.\n",
      "\n",
      "Cube_160 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 161.\n",
      "   > Found 1 clusters in hypercube 162.\n",
      "   > Found 1 clusters in hypercube 163.\n",
      "Cube_164 is empty.\n",
      "\n",
      "Cube_165 is empty.\n",
      "\n",
      "Cube_166 is empty.\n",
      "\n",
      "Cube_167 is empty.\n",
      "\n",
      "Cube_168 is empty.\n",
      "\n",
      "Cube_169 is empty.\n",
      "\n",
      "Cube_170 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 171.\n",
      "   > Found 1 clusters in hypercube 172.\n",
      "Cube_173 is empty.\n",
      "\n",
      "Cube_174 is empty.\n",
      "\n",
      "Cube_175 is empty.\n",
      "\n",
      "Cube_176 is empty.\n",
      "\n",
      "Cube_177 is empty.\n",
      "\n",
      "Cube_178 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 179.\n",
      "   > Found 1 clusters in hypercube 180.\n",
      "   > Found 1 clusters in hypercube 181.\n",
      "Cube_182 is empty.\n",
      "\n",
      "Cube_183 is empty.\n",
      "\n",
      "Cube_184 is empty.\n",
      "\n",
      "Cube_185 is empty.\n",
      "\n",
      "Cube_186 is empty.\n",
      "\n",
      "Cube_187 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 188.\n",
      "   > Found 1 clusters in hypercube 189.\n",
      "Cube_190 is empty.\n",
      "\n",
      "Cube_191 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 192.\n",
      "   > Found 1 clusters in hypercube 193.\n",
      "Cube_194 is empty.\n",
      "\n",
      "Cube_195 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 196.\n",
      "   > Found 1 clusters in hypercube 197.\n",
      "   > Found 1 clusters in hypercube 198.\n",
      "   > Found 1 clusters in hypercube 199.\n",
      "Cube_200 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 201.\n",
      "   > Found 1 clusters in hypercube 202.\n",
      "Cube_203 is empty.\n",
      "\n",
      "Cube_204 is empty.\n",
      "\n",
      "Cube_205 is empty.\n",
      "\n",
      "Cube_206 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 207.\n",
      "   > Found 1 clusters in hypercube 208.\n",
      "Cube_209 is empty.\n",
      "\n",
      "Cube_210 is empty.\n",
      "\n",
      "Cube_211 is empty.\n",
      "\n",
      "Cube_212 is empty.\n",
      "\n",
      "Cube_213 is empty.\n",
      "\n",
      "Cube_214 is empty.\n",
      "\n",
      "Cube_215 is empty.\n",
      "\n",
      "Cube_216 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 217.\n",
      "Cube_218 is empty.\n",
      "\n",
      "Cube_219 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 220.\n",
      "   > Found 1 clusters in hypercube 221.\n",
      "   > Found 1 clusters in hypercube 222.\n",
      "   > Found 1 clusters in hypercube 223.\n",
      "Cube_224 is empty.\n",
      "\n",
      "Cube_225 is empty.\n",
      "\n",
      "Cube_226 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 227.\n",
      "   > Found 1 clusters in hypercube 228.\n",
      "Cube_229 is empty.\n",
      "\n",
      "Cube_230 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 231.\n",
      "   > Found 1 clusters in hypercube 232.\n",
      "   > Found 1 clusters in hypercube 233.\n",
      "Cube_234 is empty.\n",
      "\n",
      "Cube_235 is empty.\n",
      "\n",
      "Cube_236 is empty.\n",
      "\n",
      "Cube_237 is empty.\n",
      "\n",
      "Cube_238 is empty.\n",
      "\n",
      "Cube_239 is empty.\n",
      "\n",
      "Cube_240 is empty.\n",
      "\n",
      "Cube_241 is empty.\n",
      "\n",
      "Cube_242 is empty.\n",
      "\n",
      "Cube_243 is empty.\n",
      "\n",
      "Cube_244 is empty.\n",
      "\n",
      "Cube_245 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 246.\n",
      "Cube_247 is empty.\n",
      "\n",
      "Cube_248 is empty.\n",
      "\n",
      "Cube_249 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 250.\n",
      "Cube_251 is empty.\n",
      "\n",
      "Cube_252 is empty.\n",
      "\n",
      "Cube_253 is empty.\n",
      "\n",
      "Cube_254 is empty.\n",
      "\n",
      "Cube_255 is empty.\n",
      "\n",
      "Cube_256 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 257.\n",
      "   > Found 1 clusters in hypercube 258.\n",
      "   > Found 1 clusters in hypercube 259.\n",
      "Cube_260 is empty.\n",
      "\n",
      "Cube_261 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 262.\n",
      "   > Found 1 clusters in hypercube 263.\n",
      "   > Found 1 clusters in hypercube 264.\n",
      "   > Found 1 clusters in hypercube 265.\n",
      "Cube_266 is empty.\n",
      "\n",
      "Cube_267 is empty.\n",
      "\n",
      "Cube_268 is empty.\n",
      "\n",
      "Cube_269 is empty.\n",
      "\n",
      "Cube_270 is empty.\n",
      "\n",
      "Cube_271 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 272.\n",
      "   > Found 1 clusters in hypercube 273.\n",
      "Cube_274 is empty.\n",
      "\n",
      "Cube_275 is empty.\n",
      "\n",
      "Cube_276 is empty.\n",
      "\n",
      "Cube_277 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 278.\n",
      "   > Found 1 clusters in hypercube 279.\n",
      "   > Found 1 clusters in hypercube 280.\n",
      "   > Found 1 clusters in hypercube 281.\n",
      "Cube_282 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 283.\n",
      "   > Found 1 clusters in hypercube 284.\n",
      "   > Found 1 clusters in hypercube 285.\n",
      "   > Found 1 clusters in hypercube 286.\n",
      "   > Found 1 clusters in hypercube 287.\n",
      "Cube_288 is empty.\n",
      "\n",
      "Cube_289 is empty.\n",
      "\n",
      "Cube_290 is empty.\n",
      "\n",
      "Cube_291 is empty.\n",
      "\n",
      "Cube_292 is empty.\n",
      "\n",
      "Cube_293 is empty.\n",
      "\n",
      "Cube_294 is empty.\n",
      "\n",
      "Cube_295 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 296.\n",
      "   > Found 1 clusters in hypercube 297.\n",
      "   > Found 1 clusters in hypercube 298.\n",
      "Cube_299 is empty.\n",
      "\n",
      "Cube_300 is empty.\n",
      "\n",
      "Cube_301 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 302.\n",
      "   > Found 1 clusters in hypercube 303.\n",
      "   > Found 1 clusters in hypercube 304.\n",
      "   > Found 1 clusters in hypercube 305.\n",
      "Cube_306 is empty.\n",
      "\n",
      "Cube_307 is empty.\n",
      "\n",
      "Cube_308 is empty.\n",
      "\n",
      "Cube_309 is empty.\n",
      "\n",
      "Cube_310 is empty.\n",
      "\n",
      "Cube_311 is empty.\n",
      "\n",
      "Cube_312 is empty.\n",
      "\n",
      "Cube_313 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 314.\n",
      "   > Found 1 clusters in hypercube 315.\n",
      "Cube_316 is empty.\n",
      "\n",
      "Cube_317 is empty.\n",
      "\n",
      "Cube_318 is empty.\n",
      "\n",
      "Cube_319 is empty.\n",
      "\n",
      "Cube_320 is empty.\n",
      "\n",
      "Cube_321 is empty.\n",
      "\n",
      "Cube_322 is empty.\n",
      "\n",
      "Cube_323 is empty.\n",
      "\n",
      "Cube_324 is empty.\n",
      "\n",
      "Cube_325 is empty.\n",
      "\n",
      "Cube_326 is empty.\n",
      "\n",
      "Cube_327 is empty.\n",
      "\n",
      "Cube_328 is empty.\n",
      "\n",
      "Cube_329 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 330.\n",
      "Cube_331 is empty.\n",
      "\n",
      "Cube_332 is empty.\n",
      "\n",
      "Cube_333 is empty.\n",
      "\n",
      "Cube_334 is empty.\n",
      "\n",
      "Cube_335 is empty.\n",
      "\n",
      "Cube_336 is empty.\n",
      "\n",
      "Cube_337 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 338.\n",
      "   > Found 1 clusters in hypercube 339.\n",
      "   > Found 1 clusters in hypercube 340.\n",
      "   > Found 1 clusters in hypercube 341.\n",
      "Cube_342 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 343.\n",
      "   > Found 1 clusters in hypercube 344.\n",
      "   > Found 1 clusters in hypercube 345.\n",
      "   > Found 1 clusters in hypercube 346.\n",
      "Cube_347 is empty.\n",
      "\n",
      "Cube_348 is empty.\n",
      "\n",
      "Cube_349 is empty.\n",
      "\n",
      "Cube_350 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 351.\n",
      "   > Found 1 clusters in hypercube 352.\n",
      "   > Found 1 clusters in hypercube 353.\n",
      "   > Found 1 clusters in hypercube 354.\n",
      "Cube_355 is empty.\n",
      "\n",
      "Cube_356 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 357.\n",
      "   > Found 1 clusters in hypercube 358.\n",
      "   > Found 1 clusters in hypercube 359.\n",
      "   > Found 1 clusters in hypercube 360.\n",
      "   > Found 1 clusters in hypercube 361.\n",
      "Cube_362 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 363.\n",
      "   > Found 1 clusters in hypercube 364.\n",
      "   > Found 1 clusters in hypercube 365.\n",
      "   > Found 1 clusters in hypercube 366.\n",
      "Cube_367 is empty.\n",
      "\n",
      "Cube_368 is empty.\n",
      "\n",
      "Cube_369 is empty.\n",
      "\n",
      "Cube_370 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 371.\n",
      "   > Found 1 clusters in hypercube 372.\n",
      "   > Found 1 clusters in hypercube 373.\n",
      "Cube_374 is empty.\n",
      "\n",
      "Cube_375 is empty.\n",
      "\n",
      "Cube_376 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 377.\n",
      "Cube_378 is empty.\n",
      "\n",
      "Cube_379 is empty.\n",
      "\n",
      "Cube_380 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 381.\n",
      "   > Found 1 clusters in hypercube 382.\n",
      "   > Found 1 clusters in hypercube 383.\n",
      "   > Found 1 clusters in hypercube 384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Found 1 clusters in hypercube 385.\n",
      "Cube_386 is empty.\n",
      "\n",
      "Cube_387 is empty.\n",
      "\n",
      "Cube_388 is empty.\n",
      "\n",
      "Cube_389 is empty.\n",
      "\n",
      "Cube_390 is empty.\n",
      "\n",
      "Cube_391 is empty.\n",
      "\n",
      "Cube_392 is empty.\n",
      "\n",
      "Cube_393 is empty.\n",
      "\n",
      "Cube_394 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 395.\n",
      "Cube_396 is empty.\n",
      "\n",
      "Cube_397 is empty.\n",
      "\n",
      "Cube_398 is empty.\n",
      "\n",
      "Cube_399 is empty.\n",
      "\n",
      "Cube_400 is empty.\n",
      "\n",
      "Cube_401 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 402.\n",
      "   > Found 1 clusters in hypercube 403.\n",
      "   > Found 1 clusters in hypercube 404.\n",
      "Cube_405 is empty.\n",
      "\n",
      "Cube_406 is empty.\n",
      "\n",
      "Cube_407 is empty.\n",
      "\n",
      "Cube_408 is empty.\n",
      "\n",
      "Cube_409 is empty.\n",
      "\n",
      "Cube_410 is empty.\n",
      "\n",
      "Cube_411 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 412.\n",
      "   > Found 1 clusters in hypercube 413.\n",
      "   > Found 1 clusters in hypercube 414.\n",
      "   > Found 1 clusters in hypercube 415.\n",
      "Cube_416 is empty.\n",
      "\n",
      "Cube_417 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 418.\n",
      "   > Found 1 clusters in hypercube 419.\n",
      "   > Found 1 clusters in hypercube 420.\n",
      "   > Found 1 clusters in hypercube 421.\n",
      "Cube_422 is empty.\n",
      "\n",
      "Cube_423 is empty.\n",
      "\n",
      "Cube_424 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 425.\n",
      "   > Found 1 clusters in hypercube 426.\n",
      "   > Found 1 clusters in hypercube 427.\n",
      "Cube_428 is empty.\n",
      "\n",
      "Cube_429 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 430.\n",
      "   > Found 1 clusters in hypercube 431.\n",
      "   > Found 1 clusters in hypercube 432.\n",
      "Cube_433 is empty.\n",
      "\n",
      "Cube_434 is empty.\n",
      "\n",
      "   > Found 1 clusters in hypercube 435.\n",
      "   > Found 1 clusters in hypercube 436.\n",
      "Cube_437 is empty.\n",
      "\n",
      "\n",
      "Created 369 edges and 160 nodes in 0:00:00.220000.\n",
      "Output graph examples to html\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/digits_custom_tooltips.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5cf7e34c1b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output graph examples to html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;31m# Tooltips with image data for every cluster member\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m mapper.visualize(\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Handwritten digits Mapper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kmapper\\utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mrename_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kmapper\\kmapper.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(self, graph, color_values, color_function_name, node_color_function, colorscale, custom_tooltips, custom_meta, path_html, title, save_file, X, X_names, lens, lens_names, nbins, include_searchbar)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_html\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrote visualization to: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_html\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/digits_custom_tooltips.html'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import sys\n",
    "import base64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kmapper as km\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError as e:\n",
    "    print(\"This example requires Pillow. Run `pip install pillow` and then try again.\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Load digits data\n",
    "data, labels = datasets.load_digits().data, datasets.load_digits().target\n",
    "\n",
    "# Raw data is (0, 16), so scale to 8 bits (pillow can't handle 4-bit greyscale PNG depth)\n",
    "scaler = MinMaxScaler(feature_range=(0, 255))\n",
    "data = scaler.fit_transform(data).astype(np.uint8)\n",
    "\n",
    "# Create images for a custom tooltip array\n",
    "tooltip_s = []\n",
    "for image_data in data:\n",
    "    with io.BytesIO() as output:\n",
    "        img = Image.fromarray(image_data.reshape((8, 8)), \"L\")\n",
    "        img.save(output, \"PNG\")\n",
    "        contents = output.getvalue()\n",
    "        img_encoded = base64.b64encode(contents)\n",
    "        img_tag = \"\"\"<img src=\"data:image/png;base64,{}\">\"\"\".format(\n",
    "            img_encoded.decode(\"utf-8\")\n",
    "        )\n",
    "        tooltip_s.append(img_tag)\n",
    "\n",
    "tooltip_s = np.array(\n",
    "    tooltip_s\n",
    ")  # need to make sure to feed it as a NumPy array, not a list\n",
    "\n",
    "# Initialize to use t-SNE with 2 components (reduces data to 2 dimensions). Also note high overlap_percentage.\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "# Fit and transform data\n",
    "projected_data = mapper.fit_transform(data, projection=sklearn.manifold.TSNE())\n",
    "\n",
    "# Create the graph (we cluster on the projected data and suffer projection loss)\n",
    "graph = mapper.map(\n",
    "    projected_data,\n",
    "    clusterer=sklearn.cluster.DBSCAN(eps=0.3, min_samples=15),\n",
    "    cover=km.Cover(35, 0.4),\n",
    ")\n",
    "\n",
    "# Create the visualizations (increased the graph_gravity for a tighter graph-look.)\n",
    "print(\"Output graph examples to html\")\n",
    "# Tooltips with image data for every cluster member\n",
    "mapper.visualize(\n",
    "    graph,\n",
    "    title=\"Handwritten digits Mapper\",\n",
    "    path_html=\"output/digits_custom_tooltips.html\",\n",
    "    color_values=labels,\n",
    "    color_function_name=\"labels\",\n",
    "    custom_tooltips=tooltip_s,\n",
    ")\n",
    "# Tooltips with the target y-labels for every cluster member\n",
    "mapper.visualize(\n",
    "    graph,\n",
    "    title=\"Handwritten digits Mapper\",\n",
    "    path_html=\"output/digits_ylabel_tooltips.html\",\n",
    "    custom_tooltips=labels,\n",
    ")\n",
    "\n",
    "# Matplotlib examples\n",
    "km.draw_matplotlib(graph, layout=\"spring\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cube1_cluster0', 'cube2_cluster0', 'cube5_cluster0', 'cube6_cluster0', 'cube7_cluster0', 'cube10_cluster0', 'cube11_cluster0', 'cube12_cluster0', 'cube17_cluster0', 'cube18_cluster0', 'cube19_cluster0', 'cube23_cluster0', 'cube24_cluster0', 'cube27_cluster0', 'cube28_cluster0', 'cube29_cluster0', 'cube33_cluster0', 'cube34_cluster0', 'cube35_cluster0', 'cube36_cluster0', 'cube47_cluster0', 'cube48_cluster0', 'cube52_cluster0', 'cube53_cluster0', 'cube54_cluster0', 'cube55_cluster0', 'cube58_cluster0', 'cube60_cluster0', 'cube61_cluster0', 'cube69_cluster0', 'cube71_cluster0', 'cube72_cluster0', 'cube75_cluster0', 'cube77_cluster0', 'cube78_cluster0', 'cube79_cluster0', 'cube89_cluster0', 'cube93_cluster0', 'cube94_cluster0', 'cube95_cluster0', 'cube107_cluster0', 'cube108_cluster0', 'cube109_cluster0', 'cube120_cluster0', 'cube121_cluster0', 'cube134_cluster0', 'cube145_cluster0', 'cube147_cluster0', 'cube148_cluster0', 'cube153_cluster0', 'cube161_cluster0', 'cube162_cluster0', 'cube163_cluster0', 'cube171_cluster0', 'cube172_cluster0', 'cube179_cluster0', 'cube180_cluster0', 'cube181_cluster0', 'cube188_cluster0', 'cube189_cluster0', 'cube192_cluster0', 'cube193_cluster0', 'cube196_cluster0', 'cube197_cluster0', 'cube198_cluster0', 'cube199_cluster0', 'cube201_cluster0', 'cube202_cluster0', 'cube207_cluster0', 'cube208_cluster0', 'cube217_cluster0', 'cube220_cluster0', 'cube221_cluster0', 'cube222_cluster0', 'cube223_cluster0', 'cube227_cluster0', 'cube228_cluster0', 'cube231_cluster0', 'cube232_cluster0', 'cube233_cluster0', 'cube246_cluster0', 'cube250_cluster0', 'cube257_cluster0', 'cube258_cluster0', 'cube259_cluster0', 'cube262_cluster0', 'cube263_cluster0', 'cube264_cluster0', 'cube265_cluster0', 'cube272_cluster0', 'cube273_cluster0', 'cube278_cluster0', 'cube279_cluster0', 'cube280_cluster0', 'cube281_cluster0', 'cube283_cluster0', 'cube284_cluster0', 'cube285_cluster0', 'cube286_cluster0', 'cube287_cluster0', 'cube296_cluster0', 'cube297_cluster0', 'cube298_cluster0', 'cube302_cluster0', 'cube303_cluster0', 'cube304_cluster0', 'cube305_cluster0', 'cube314_cluster0', 'cube315_cluster0', 'cube330_cluster0', 'cube338_cluster0', 'cube339_cluster0', 'cube340_cluster0', 'cube341_cluster0', 'cube343_cluster0', 'cube344_cluster0', 'cube345_cluster0', 'cube346_cluster0', 'cube351_cluster0', 'cube352_cluster0', 'cube353_cluster0', 'cube354_cluster0', 'cube357_cluster0', 'cube358_cluster0', 'cube359_cluster0', 'cube360_cluster0', 'cube361_cluster0', 'cube363_cluster0', 'cube364_cluster0', 'cube365_cluster0', 'cube366_cluster0', 'cube371_cluster0', 'cube372_cluster0', 'cube373_cluster0', 'cube377_cluster0', 'cube381_cluster0', 'cube382_cluster0', 'cube383_cluster0', 'cube384_cluster0', 'cube385_cluster0', 'cube395_cluster0', 'cube402_cluster0', 'cube403_cluster0', 'cube404_cluster0', 'cube412_cluster0', 'cube413_cluster0', 'cube414_cluster0', 'cube415_cluster0', 'cube418_cluster0', 'cube419_cluster0', 'cube420_cluster0', 'cube421_cluster0', 'cube425_cluster0', 'cube426_cluster0', 'cube427_cluster0', 'cube430_cluster0', 'cube431_cluster0', 'cube432_cluster0', 'cube435_cluster0', 'cube436_cluster0'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.494470605216406,\n",
       " 0.5250811683319966,\n",
       " 0.5547656501215521,\n",
       " 0.5144832340140439,\n",
       " 0.5557590717707123,\n",
       " 0.5798432533244197,\n",
       " 0.5286613494601218,\n",
       " 0.5448111166624332,\n",
       " 0.5061459647127453,\n",
       " 0.48965169334776,\n",
       " 0.5017295517886569,\n",
       " 0.5463011773175607,\n",
       " 0.505220566237519,\n",
       " 0.5348211731395368,\n",
       " 0.49520881391574945,\n",
       " 0.5259546481101841,\n",
       " 0.488567395814133,\n",
       " 0.5204826880770703,\n",
       " 0.5002968183460869,\n",
       " 0.5064907389420243,\n",
       " 0.4720709129958684,\n",
       " 0.5257091922318812,\n",
       " 0.5302710699725586,\n",
       " 0.46972199642805074,\n",
       " 0.5270392002988917,\n",
       " 0.5278593229358283,\n",
       " 0.5956158100141586,\n",
       " 0.5594269558970423,\n",
       " 0.528827570599993,\n",
       " 0.6208487964126188,\n",
       " 0.5291657939375259,\n",
       " 0.5489183651589353,\n",
       " 0.5531947177186987,\n",
       " 0.5761076915977023,\n",
       " 0.46897727852354254,\n",
       " 0.4755360456127137,\n",
       " 0.574134370262166,\n",
       " 0.5447774165134499,\n",
       " 0.513736123606663,\n",
       " 0.5490786200122357,\n",
       " 0.5607465765024948,\n",
       " 0.559090532773815,\n",
       " 0.5594032811721665,\n",
       " 0.5561676175344578,\n",
       " 0.511115765666528,\n",
       " 0.49410846461220925,\n",
       " 0.42782032596116865,\n",
       " 0.611637002015326,\n",
       " 0.5650885915037964,\n",
       " 0.5221860589794874,\n",
       " 0.5497506098330036,\n",
       " 0.4905914106343766,\n",
       " 0.4661542073503147,\n",
       " 0.43569040743156445,\n",
       " 0.3934445289740648,\n",
       " 0.5360432719589557,\n",
       " 0.5593086966731885,\n",
       " 0.4883335611313327,\n",
       " 0.4768418383275145,\n",
       " 0.4252239377755879,\n",
       " 0.4613100451214531,\n",
       " 0.4510508319988701,\n",
       " 0.542317874541885,\n",
       " 0.5683347759170242,\n",
       " 0.5599962272449545,\n",
       " 0.5591670338459734,\n",
       " 0.5428434220821996,\n",
       " 0.5436561725735507,\n",
       " 0.5099122705155511,\n",
       " 0.5015622797109146,\n",
       " 0.4932386553351153,\n",
       " 0.5276492122647294,\n",
       " 0.5619575902474282,\n",
       " 0.5603540174168289,\n",
       " 0.5482368700840026,\n",
       " 0.5249743755542837,\n",
       " 0.563464320481334,\n",
       " 0.5960694359583216,\n",
       " 0.5620603570429874,\n",
       " 0.60203659710518,\n",
       " 0.5670885430288928,\n",
       " 0.515325721389375,\n",
       " 0.566898948275469,\n",
       " 0.5272779365160954,\n",
       " 0.584156461203124,\n",
       " 0.5271806085126337,\n",
       " 0.5614420608538504,\n",
       " 0.5542786427895209,\n",
       " 0.4671664439560089,\n",
       " 0.5473905489131673,\n",
       " 0.5076714726831044,\n",
       " 0.5131471421045606,\n",
       " 0.5310475078821111,\n",
       " 0.5622603612393223,\n",
       " 0.5899597260372091,\n",
       " 0.48312776201654356,\n",
       " 0.5171607670176755,\n",
       " 0.5485762202484633,\n",
       " 0.5427863632964567,\n",
       " 0.46485829501464554,\n",
       " 0.48808901077553696,\n",
       " 0.5092753636629032,\n",
       " 0.5677857616667455,\n",
       " 0.5634158580520101,\n",
       " 0.5194863686038902,\n",
       " 0.5007136564754594,\n",
       " 0.4901024737756198,\n",
       " 0.5559439193380236,\n",
       " 0.4814791289047061,\n",
       " 0.4692228134472276,\n",
       " 0.5233546659084323,\n",
       " 0.5128764504610328,\n",
       " 0.5104701269789246,\n",
       " 0.5066725874994884,\n",
       " 0.5065945765264982,\n",
       " 0.5091259014850267,\n",
       " 0.5625440724986109,\n",
       " 0.578736851687798,\n",
       " 0.5976137196659725,\n",
       " 0.5545598605369789,\n",
       " 0.5434968131368435,\n",
       " 0.5589201929116996,\n",
       " 0.5386452956828348,\n",
       " 0.5655084294664436,\n",
       " 0.5920705955576007,\n",
       " 0.48541976829974953,\n",
       " 0.5025353007632626,\n",
       " 0.5738660218780985,\n",
       " 0.5353843716187398,\n",
       " 0.5096375560400633,\n",
       " 0.5388773700700751,\n",
       " 0.510541982830819,\n",
       " 0.5179255056493158,\n",
       " 0.5476730354561149,\n",
       " 0.5776364167592453,\n",
       " 0.5551462847784823,\n",
       " 0.5435717290848232,\n",
       " 0.5131247216959371,\n",
       " 0.5323961837331143,\n",
       " 0.5568616723407627,\n",
       " 0.5623643561863563,\n",
       " 0.5297603802313555,\n",
       " 0.5094658327897994,\n",
       " 0.4489609307953224,\n",
       " 0.5285087875547401,\n",
       " 0.5340154031331634,\n",
       " 0.5319181979640465,\n",
       " 0.506203083609327,\n",
       " 0.5802585898109827,\n",
       " 0.5652707055857311,\n",
       " 0.5853815401262383,\n",
       " 0.5953971858147962,\n",
       " 0.5559782036575399,\n",
       " 0.5095180177171497,\n",
       " 0.5166338330589436,\n",
       " 0.5337297965464887,\n",
       " 0.5245655165453166,\n",
       " 0.48951265099376906,\n",
       " 0.5723313114642942,\n",
       " 0.5366155831430941]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "graphlens = []\n",
    "for points in graph[\"nodes\"].values():\n",
    "    if points == []:\n",
    "        continue\n",
    "    graphlens.append(mean([lens[i][0] for i in points]))\n",
    "print(graph[\"nodes\"].keys())\n",
    "\n",
    "import networkx as nx\n",
    "nx_graph = km.adapter.to_nx(graph)\n",
    "nx.write_graph6(nx_graph,\"digits.graph6\")\n",
    "\n",
    "graphlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphlens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper(verbose=2)\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: sum\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (7207, 3)\n",
      "\n",
      "..Projecting data using: sum\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "Mapping on data shaped (7207, 3) using lens shaped (7207, 1)\n",
      "\n",
      "Minimal points in hypercube before clustering: 5\n",
      "Creating 15 hypercubes.\n",
      "   > Found 2 clusters in hypercube 0.\n",
      "   > Found 2 clusters in hypercube 1.\n",
      "   > Found 2 clusters in hypercube 2.\n",
      "   > Found 1 clusters in hypercube 3.\n",
      "   > Found 2 clusters in hypercube 4.\n",
      "   > Found 2 clusters in hypercube 5.\n",
      "   > Found 1 clusters in hypercube 6.\n",
      "   > Found 1 clusters in hypercube 7.\n",
      "   > Found 1 clusters in hypercube 8.\n",
      "   > Found 1 clusters in hypercube 9.\n",
      "   > Found 1 clusters in hypercube 10.\n",
      "   > Found 1 clusters in hypercube 11.\n",
      "   > Found 1 clusters in hypercube 12.\n",
      "   > Found 1 clusters in hypercube 13.\n",
      "   > Found 1 clusters in hypercube 14.\n",
      "\n",
      "Created 19 edges and 20 nodes in 0:00:00.114535.\n",
      "Wrote visualization to: cat.html\n",
      "dict_keys(['cube0_cluster0', 'cube0_cluster1', 'cube1_cluster0', 'cube1_cluster1', 'cube2_cluster0', 'cube2_cluster1', 'cube3_cluster0', 'cube4_cluster0', 'cube4_cluster1', 'cube5_cluster0', 'cube5_cluster1', 'cube6_cluster0', 'cube7_cluster0', 'cube8_cluster0', 'cube9_cluster0', 'cube10_cluster0', 'cube11_cluster0', 'cube12_cluster0', 'cube13_cluster0', 'cube14_cluster0'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05821261969831075,\n",
       " 0.031150753583003548,\n",
       " 0.08954872397051421,\n",
       " 0.09857525385113208,\n",
       " 0.16629887151321296,\n",
       " 0.16476644766417609,\n",
       " 0.2336163493160702,\n",
       " 0.29731944709888036,\n",
       " 0.34000858078143714,\n",
       " 0.36313136300937987,\n",
       " 0.37699007243025967,\n",
       " 0.4366291077891086,\n",
       " 0.4905688524345674,\n",
       " 0.5662495918092447,\n",
       " 0.6320591064182264,\n",
       " 0.7009019680051876,\n",
       " 0.7713299046859922,\n",
       " 0.842344226540508,\n",
       " 0.8952833587938017,\n",
       " 0.945359228014147]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import kmapper as km\n",
    "import numpy as np\n",
    "data = np.genfromtxt(\"data/cat-reference.csv\", delimiter=\",\")\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "lens = mapper.fit_transform(data)\n",
    "\n",
    "graph = mapper.map(\n",
    "    lens,\n",
    "    data,\n",
    "    clusterer=sklearn.cluster.DBSCAN(eps=0.1, min_samples=5),\n",
    "    cover=km.Cover(n_cubes=15, perc_overlap=0.2),\n",
    ")\n",
    "\n",
    "mapper.visualize(graph, path_html=\"cat.html\")\n",
    "\n",
    "from statistics import mean\n",
    "graphlens = []\n",
    "for points in graph[\"nodes\"].values():\n",
    "    if points == []:\n",
    "        continue\n",
    "    graphlens.append(mean([lens[i][0] for i in points]))\n",
    "print(graph[\"nodes\"].keys())\n",
    "\n",
    "import networkx as nx\n",
    "nx_graph = km.adapter.to_nx(graph)\n",
    "nx.write_graph6(nx_graph,\"cat.graph6\")\n",
    "\n",
    "graphlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper(verbose=2)\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: sum\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (5000, 3)\n",
      "\n",
      "..Projecting data using: sum\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "Mapping on data shaped (5000, 3) using lens shaped (5000, 1)\n",
      "\n",
      "Minimal points in hypercube before clustering: 5\n",
      "Creating 15 hypercubes.\n",
      "   > Found 1 clusters in hypercube 0.\n",
      "   > Found 2 clusters in hypercube 1.\n",
      "   > Found 3 clusters in hypercube 2.\n",
      "   > Found 2 clusters in hypercube 3.\n",
      "   > Found 1 clusters in hypercube 4.\n",
      "   > Found 2 clusters in hypercube 5.\n",
      "   > Found 2 clusters in hypercube 6.\n",
      "   > Found 1 clusters in hypercube 7.\n",
      "   > Found 1 clusters in hypercube 8.\n",
      "   > Found 1 clusters in hypercube 9.\n",
      "   > Found 1 clusters in hypercube 10.\n",
      "   > Found 1 clusters in hypercube 11.\n",
      "   > Found 1 clusters in hypercube 12.\n",
      "   > Found 1 clusters in hypercube 13.\n",
      "   > Found 1 clusters in hypercube 14.\n",
      "\n",
      "Created 20 edges and 21 nodes in 0:00:00.079892.\n",
      "Wrote visualization to: lion.html\n",
      "dict_keys(['cube0_cluster0', 'cube1_cluster0', 'cube1_cluster1', 'cube2_cluster0', 'cube2_cluster1', 'cube2_cluster2', 'cube3_cluster0', 'cube3_cluster1', 'cube4_cluster0', 'cube5_cluster0', 'cube5_cluster1', 'cube6_cluster0', 'cube6_cluster1', 'cube7_cluster0', 'cube8_cluster0', 'cube9_cluster0', 'cube10_cluster0', 'cube11_cluster0', 'cube12_cluster0', 'cube13_cluster0', 'cube14_cluster0'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.039928079328225216,\n",
       " 0.08831831147617844,\n",
       " 0.1147018731037132,\n",
       " 0.18712375836228468,\n",
       " 0.15467059782315284,\n",
       " 0.15813593981707055,\n",
       " 0.22686088057832582,\n",
       " 0.23308245655207782,\n",
       " 0.30025938194582186,\n",
       " 0.36300185980417926,\n",
       " 0.3981066300055593,\n",
       " 0.43002419150092447,\n",
       " 0.4345483791127312,\n",
       " 0.5044392501848346,\n",
       " 0.5656462748697907,\n",
       " 0.6242883899864906,\n",
       " 0.699988505169165,\n",
       " 0.7790166017524458,\n",
       " 0.8403023414143805,\n",
       " 0.8974501211116412,\n",
       " 0.9555435933561892]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import kmapper as km\n",
    "import numpy as np\n",
    "data = np.genfromtxt(\"data/lion-reference.csv\", delimiter=\",\")\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "lens = mapper.fit_transform(data)\n",
    "\n",
    "graph = mapper.map(\n",
    "    lens,\n",
    "    data,\n",
    "    clusterer=sklearn.cluster.DBSCAN(eps=0.1, min_samples=5),\n",
    "    cover=km.Cover(n_cubes=15, perc_overlap=0.2),\n",
    ")\n",
    "\n",
    "mapper.visualize(graph, path_html=\"lion.html\")\n",
    "\n",
    "from statistics import mean\n",
    "graphlens = []\n",
    "for points in graph[\"nodes\"].values():\n",
    "    if points == []:\n",
    "        continue\n",
    "    graphlens.append(mean([lens[i][0] for i in points]))\n",
    "print(graph[\"nodes\"].keys())\n",
    "\n",
    "import networkx as nx\n",
    "nx_graph = km.adapter.to_nx(graph)\n",
    "nx.write_graph6(nx_graph,\"lion.graph6\")\n",
    "\n",
    "graphlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper(verbose=2)\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: sum\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (8431, 3)\n",
      "\n",
      "..Projecting data using: sum\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "Mapping on data shaped (8431, 3) using lens shaped (8431, 1)\n",
      "\n",
      "Minimal points in hypercube before clustering: 5\n",
      "Creating 15 hypercubes.\n",
      "   > Found 2 clusters in hypercube 0.\n",
      "   > Found 3 clusters in hypercube 1.\n",
      "   > Found 3 clusters in hypercube 2.\n",
      "   > Found 2 clusters in hypercube 3.\n",
      "   > Found 2 clusters in hypercube 4.\n",
      "   > Found 2 clusters in hypercube 5.\n",
      "   > Found 1 clusters in hypercube 6.\n",
      "   > Found 1 clusters in hypercube 7.\n",
      "   > Found 1 clusters in hypercube 8.\n",
      "   > Found 1 clusters in hypercube 9.\n",
      "   > Found 1 clusters in hypercube 10.\n",
      "   > Found 1 clusters in hypercube 11.\n",
      "   > Found 1 clusters in hypercube 12.\n",
      "   > Found 1 clusters in hypercube 13.\n",
      "   > Found 1 clusters in hypercube 14.\n",
      "\n",
      "Created 22 edges and 23 nodes in 0:00:00.119720.\n",
      "Wrote visualization to: horse.html\n",
      "dict_keys(['cube0_cluster0', 'cube0_cluster1', 'cube1_cluster0', 'cube1_cluster1', 'cube1_cluster2', 'cube2_cluster0', 'cube2_cluster1', 'cube2_cluster2', 'cube3_cluster0', 'cube3_cluster1', 'cube4_cluster0', 'cube4_cluster1', 'cube5_cluster0', 'cube5_cluster1', 'cube6_cluster0', 'cube7_cluster0', 'cube8_cluster0', 'cube9_cluster0', 'cube10_cluster0', 'cube11_cluster0', 'cube12_cluster0', 'cube13_cluster0', 'cube14_cluster0'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0430658109471472,\n",
       " 0.0690867702967714,\n",
       " 0.11994831346252788,\n",
       " 0.09758857269880156,\n",
       " 0.1080859664445717,\n",
       " 0.16389740748346315,\n",
       " 0.16238086727824272,\n",
       " 0.16402253353788693,\n",
       " 0.23289411545642125,\n",
       " 0.27092283070524437,\n",
       " 0.2977037675689274,\n",
       " 0.3106494792633316,\n",
       " 0.36055878985824985,\n",
       " 0.37374464157984083,\n",
       " 0.43204056519908346,\n",
       " 0.4964080660235876,\n",
       " 0.5662378313865974,\n",
       " 0.6289727458229478,\n",
       " 0.6955275146233175,\n",
       " 0.7658797243916117,\n",
       " 0.843413566046764,\n",
       " 0.9051344139088321,\n",
       " 0.961966923337052]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import kmapper as km\n",
    "import numpy as np\n",
    "data = np.genfromtxt(\"data/horse-reference.csv\", delimiter=\",\")\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=2)\n",
    "\n",
    "lens = mapper.fit_transform(data)\n",
    "\n",
    "graph = mapper.map(\n",
    "    lens,\n",
    "    data,\n",
    "    clusterer=sklearn.cluster.DBSCAN(eps=0.1, min_samples=5),\n",
    "    cover=km.Cover(n_cubes=15, perc_overlap=0.2),\n",
    ")\n",
    "\n",
    "mapper.visualize(graph, path_html=\"horse.html\")\n",
    "\n",
    "from statistics import mean\n",
    "graphlens = []\n",
    "for points in graph[\"nodes\"].values():\n",
    "    if points == []:\n",
    "        continue\n",
    "    graphlens.append(mean([lens[i][0] for i in points]))\n",
    "print(graph[\"nodes\"].keys())\n",
    "\n",
    "import networkx as nx\n",
    "nx_graph = km.adapter.to_nx(graph)\n",
    "nx.write_graph6(nx_graph,\"horse.graph6\")\n",
    "\n",
    "graphlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer\n",
    "\n",
    "This example generates a Mapper built from the `Wisconsin Breast Cancer Dataset`_.\n",
    "\n",
    "\n",
    "\n",
    "The reasoning behind the choice of lenses in the demonstration below is:\n",
    "\n",
    "- **For lens1:** Lenses that make biological sense; in other words, lenses that highlight special features in the data, that I know about.\n",
    "- **For lens2:** Lenses that disperse the data, as opposed to clustering many points together.\n",
    "\n",
    "In the case of this particular data, using an anomaly score (in this case calculated using the IsolationForest from sklearn) makes biological sense since cancer cells are anomalous. For the second lens, we use the $l^2$ norm.\n",
    "\n",
    "For an interactive exploration of lens for the breast cancer, see the `Choosing a lens notebook <../../notebooks/Cancer-demo.html>`_.\n",
    "\n",
    "KeplerMapper also permits setting multiple datapoint color functions and node color functions in its html visualizations.\n",
    "The example code below demonstrates three ways this might be done. The rendered visualizations are also viewable:\n",
    "\n",
    "- `Visualization of the breat cancer mapper using multiple datapoint color functions <../../_static/breast-cancer-multiple-color-functions.html>`_\n",
    "- `Visualization of the breat cancer mapper using multiple node color functions <../../_static/breast-cancer-multiple-node-color-functions.html>`_\n",
    "- `Visualization of the breat cancer mapper using multiple datapoint and node color functions <../../_static/breast-cancer-multiple-color-functions-and-multiple-node-color-functions.html>`_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as e:\n",
    "    print(\n",
    "        \"pandas is required for this example. Please install with `pip install pandas` and then try again.\"\n",
    "    )\n",
    "    sys.exit()\n",
    "\n",
    "import numpy as np\n",
    "import kmapper as km\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "\n",
    "# For data we use the Wisconsin Breast Cancer Dataset\n",
    "# Via:\n",
    "df = pd.read_csv(\"data/breast-cancer.csv\")\n",
    "feature_names = [c for c in df.columns if c not in [\"id\", \"diagnosis\"]]\n",
    "df[\"diagnosis\"] = df[\"diagnosis\"].apply(lambda x: 1 if x == \"M\" else 0)\n",
    "X = np.array(df[feature_names].fillna(0))  # quick and dirty imputation\n",
    "y = np.array(df[\"diagnosis\"])\n",
    "\n",
    "# We create a custom 1-D lens with Isolation Forest\n",
    "model = ensemble.IsolationForest(random_state=1729)\n",
    "model.fit(X)\n",
    "lens1 = model.decision_function(X).reshape((X.shape[0], 1))\n",
    "\n",
    "# We create another 1-D lens with L2-norm\n",
    "mapper = km.KeplerMapper(verbose=3)\n",
    "lens2 = mapper.fit_transform(X, projection=\"l2norm\")\n",
    "\n",
    "# Combine both lenses to create a 2-D [Isolation Forest, L^2-Norm] lens\n",
    "lens = np.c_[lens1, lens2]\n",
    "\n",
    "# Create the simplicial complex\n",
    "graph = mapper.map(\n",
    "    lens,\n",
    "    X,\n",
    "    cover=km.Cover(n_cubes=15, perc_overlap=0.4),\n",
    "    clusterer=sklearn.cluster.KMeans(n_clusters=2, random_state=1618033),\n",
    ")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "km.draw_matplotlib(graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nx_graph = km.adapter.to_nx(graph)\n",
    "nx.generate_graphml(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "graphlens = []\n",
    "for points in graph[\"nodes\"].values():\n",
    "    if points == []:\n",
    "        continue\n",
    "    graphlens.append(mean([lens[i][0] for i in points]))\n",
    "print(graph[\"nodes\"].keys())\n",
    "\n",
    "graphlens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
